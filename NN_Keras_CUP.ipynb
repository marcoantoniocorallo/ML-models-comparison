{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress debugging information about GPU\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import os.path\n",
    "import sys\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import mean, std\n",
    "from keras.initializers import RandomUniform, GlorotUniform, Zeros\n",
    "from keras.layers import Dense, InputLayer\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import L2, L1\n",
    "from keras.callbacks import Callback\n",
    "from keras.optimizers.schedules import PolynomialDecay, ExponentialDecay\n",
    "from scikeras.wrappers import KerasRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from cup_helpers import *\n",
    "\n",
    "# set random seed for reproducible experiments\n",
    "tf.random.set_seed(42)\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read CSV dataset\n",
    "def read_ds_df(path):\n",
    "  \"\"\"\n",
    "  parse CSV data set and\n",
    "  returns a tuple (input, target)\n",
    "  \"\"\"\n",
    "  names = [\"id\", \"INPUT_0\", \"INPUT_1\", \"INPUT_2\", \"INPUT_3\", \"INPUT_4\", \"INPUT_5\", \"INPUT_6\", \"INPUT_7\", \"INPUT_8\", \"INPUT_9\", \"TARGET_x\", \"TARGET_y\", \"TARGET_z\"]\n",
    "  data = pd.read_csv(path, dtype=object, delimiter=\",\", header=None, skiprows=1, names=names)\n",
    "  y = data.drop([\"id\",\"INPUT_0\", \"INPUT_1\", \"INPUT_2\", \"INPUT_3\", \"INPUT_4\", \"INPUT_5\", \"INPUT_6\", \"INPUT_7\", \"INPUT_8\", \"INPUT_9\"], axis=1)\n",
    "  X = data.drop([\"id\",\"TARGET_x\", \"TARGET_y\", \"TARGET_z\"], axis=1).astype(float)\n",
    "  y = y.astype(float)\n",
    "\n",
    "  return (X , y)\n",
    "\n",
    "# read CSV blind test-set\n",
    "def read_ts_df(path):\n",
    "  names = ['id','input0', 'input1', 'input2', 'input3', 'input4', 'input5', 'input6', 'input7', 'input8', 'input9']\n",
    "  df = pd.read_csv(path, names=names, dtype=object, header=None, skipinitialspace=True, skiprows=7)\n",
    "  return df.drop(['id'],axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing: load and split dataset\n",
    "(X, y) = read_ds_df(\"data/ML-CUP23-TR.csv\")\n",
    "\n",
    "#split 80% dev and 20% train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=SEED, shuffle=True)\n",
    "\n",
    "# blind test set\n",
    "blind_test = read_ts_df(\"data/ML-CUP23-TS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Euclidean Error metric for sklearn GridSearchCV\n",
    "def mee(hx, y):\n",
    "\n",
    "  if y.ndim > 1:\n",
    "    l2_norms = np.linalg.norm(np.subtract(hx, y), axis=1)\n",
    "    return mean(l2_norms, axis=0)\n",
    "  else:\n",
    "    l2_norms = []\n",
    "    for p in range(len(y)):\n",
    "      l2_norms.append(np.linalg.norm(np.subtract(hx[p], y[p])))\n",
    "    return mean(l2_norms)\n",
    "      \n",
    "custom_scores = {\n",
    "  \"mee\": make_scorer(mee, greater_is_better=False)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom metric to introduce mee on Keras\n",
    "@tf.autograph.experimental.do_not_convert\n",
    "def mee_NN(hx, y):\n",
    "  error = y - hx\n",
    "  l2_norm = tf.norm(error, ord=2, axis=1)\n",
    "  return tf.keras.backend.mean(l2_norm, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_NN: Function that builds up a NN\n",
    "def get_NN(X_len, initializer=\"random\", seed=42, hidden_layers=[{\"neurons\":4,\"activation\":\"tanh\"}],\n",
    "          lr=0.01, alpha=0.5, lambda_reg=None, penalty=None, nesterov=False):\n",
    "\n",
    "  # weight initialization\n",
    "  init, bias = (GlorotUniform(seed=seed), Zeros())  if initializer==\"glorot\" \\\n",
    "          else (RandomUniform(seed=seed), RandomUniform(seed=seed))\n",
    "\n",
    "  # regularization\n",
    "  regularizer = L1(l1=lambda_reg) if penalty == \"L1\" \\\n",
    "          else  L2(l2=lambda_reg) if penalty == \"L2\" \\\n",
    "          else  None\n",
    "\n",
    "  # 1 hidden layer\n",
    "  NN_model = Sequential()\n",
    "  NN_model.add(InputLayer(input_shape=(X_len,)))\n",
    "\n",
    "  for layer in hidden_layers:\n",
    "    NN_model.add(Dense(layer[\"neurons\"],  activation=layer[\"activation\"], \n",
    "                kernel_initializer=init, bias_initializer=bias, kernel_regularizer=regularizer)\n",
    "    )\n",
    "\n",
    "  # output layer\n",
    "  NN_model.add(Dense(units=3, activation = \"linear\", kernel_initializer=init, \n",
    "              bias_initializer=bias, kernel_regularizer=regularizer)\n",
    "  )\n",
    "\n",
    "  NN_model.compile(optimizer=SGD(learning_rate=lr, momentum=alpha, nesterov=nesterov), loss=mee_NN )\n",
    "  \n",
    "  return NN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities to get the mean of K histories\n",
    "\n",
    "def add_padding(ls, n):\n",
    "  ls.extend([ls[-1]] * n)\n",
    "  return ls\n",
    "\n",
    "def longest(ls):\n",
    "  return len(max(ls, key=(lambda history : len(history['loss'])))['loss'])\n",
    "\n",
    "def mean_epochs(l):\n",
    "  return int(mean([ len(item['loss']) for item in l ]))\n",
    "\n",
    "def mean_history(_histories):\n",
    "  m = mean_epochs(_histories)+1\n",
    "  # m = longest(_histories)\n",
    "  for history in _histories:\n",
    "    l = len(history['loss'])\n",
    "    for field in _histories[0]:\n",
    "      if l>= m:\n",
    "        history[field] = history[field][:m]\n",
    "      else:\n",
    "        history[field] = add_padding(history[field], (m-l))\n",
    "  return \\\n",
    "    { field : \n",
    "        [ \n",
    "          (sum(x)/len(_histories)) for x in zip(\n",
    "            *[ history[field] for history in _histories ]\n",
    "          )\n",
    "        ] for field in _histories[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static fold counter\n",
    "def count():\n",
    "  count.count += 1\n",
    "  return count.count\n",
    "\n",
    "def reset_counter():\n",
    "  count.count =-1\n",
    "\n",
    "def get_count():\n",
    "  return count.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static history register\n",
    "def histories():\n",
    "  histories.histories = []\n",
    "\n",
    "def register(h):\n",
    "  histories.histories.append(h)\n",
    "\n",
    "def get_histories():\n",
    "  return histories.histories\n",
    "\n",
    "def clear_histories():\n",
    "  histories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot utility\n",
    "def do_NN_plot(history):\n",
    "  plt.plot(history['loss'])\n",
    "  plt.plot(history['val_loss'],  linestyle=\"--\", color=\"orange\")\n",
    "  plt.title(f'model MEE')\n",
    "  plt.ylabel('MEE')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['training', 'test'], loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KerasRegressor Wrapper for kfold\n",
    "class KRWrapper(KerasRegressor):\n",
    "\n",
    "  def __init__(self, val_data, k, *args, **kwargs):\n",
    "    super(KRWrapper, self).__init__(*args, **kwargs)\n",
    "    self.val_data = val_data\n",
    "    self.k = k\n",
    "    \n",
    "  def fit(self, X, y, **kwargs):\n",
    "    h = super().fit(X, y, validation_data=self.val_data[count()], **kwargs)\n",
    "    register(h.history_)\n",
    "    # do_NN_plot(h.history_)  # plot single fold curve\n",
    "    if self.kfold_finished(): # plot mean of k folds curves\n",
    "      do_NN_plot(mean_history(get_histories()))\n",
    "    \n",
    "  def kfold_finished(self):\n",
    "    return self.k == get_count()+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr decay strategies\n",
    "\n",
    "linear_lr_decay0 = PolynomialDecay(\n",
    "  0.01,\n",
    "  200,\n",
    "  end_learning_rate=0.0005,\n",
    "  power=1.0,\n",
    "  name=\"lr_decay0\"\n",
    ")\n",
    "\n",
    "linear_lr_decay1 = PolynomialDecay(\n",
    "  0.01,\n",
    "  250,\n",
    "  end_learning_rate=0.0005,\n",
    "  power=0.5,\n",
    "  cycle=False,\n",
    "  name=\"lr_decay1\"\n",
    ")\n",
    "\n",
    "linear_lr_decay2 = PolynomialDecay(\n",
    "  0.01,\n",
    "  250,\n",
    "  end_learning_rate=0.0005,\n",
    "  power=0.5,\n",
    "  cycle=True,\n",
    "  name=\"lr_decay2\"\n",
    ")\n",
    "\n",
    "exp_lr_decay0 = ExponentialDecay(\n",
    "  0.2,\n",
    "  decay_steps=1000,\n",
    "  decay_rate=0.8,\n",
    ")\n",
    "\n",
    "exp_lr_decay1 = ExponentialDecay(\n",
    "  0.2,\n",
    "  decay_steps=1000,\n",
    "  decay_rate=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grids for gridsearchcv\n",
    "kerasRegressorParams = {\n",
    "  \"model\" : get_NN,\n",
    "  \"X_len\" : len(X_train.columns),\n",
    "  \"loss\" : mee_NN,\n",
    "  \"optimizer\" : \"SGD\", # fixed into get_NN\n",
    "  \"batch_size\" : 32,\n",
    "  \"epochs\" : 2000,\n",
    "  \"shuffle\" : True,\n",
    "  \"verbose\" : 0\n",
    "}\n",
    "\n",
    "NN = KerasRegressor(**kerasRegressorParams)\n",
    "\n",
    "GRID_DICT = {\n",
    "  # \"batch_size\" : [8, 25, 32, 64, 128, 500],\n",
    "  \"model__lr\" : [linear_lr_decay2], # [0.01, 0.001, 0.005, linear_lr_decay0,linear_lr_decay2, exp_lr_decay1, exp_lr_decay0],\n",
    "  \"model__alpha\" : [0.9], # [0.5, 0.6, 0.7, 0.8, 0.85, 0.9],\n",
    "  \"model__initializer\" : [\"glorot\"], # [\"random\", \"glorot\"]\n",
    "  \"model__nesterov\" : [True], # [True, False]\n",
    "  \"model__penalty\": [\"L1\"], # [None, \"L1\", \"L2\"],\n",
    "  \"model__lambda_reg\": [0.0005], # [0.01, 0.001, 0.0001, 0.0005],\n",
    "  \"model__seed\" : [15],\n",
    "  \"model__hidden_layers\" : [  # [ <256, tanh>, <512, tanh>, <128, tanh> ], [ <128, relu>, <256, relu>, <64, relu> ]\n",
    "    [                         # [ <64, relu>, <128, relu>, <256, relu>, <64, relu> ], [ <64, tanh>, <256, tanh>, <32, tanh> ]\n",
    "      { \n",
    "        \"neurons\": 128, \n",
    "        \"activation\":\"tanh\" \n",
    "      }, \n",
    "      {\n",
    "        \"neurons\": 256,\n",
    "        \"activation\":\"tanh\" \n",
    "      },\n",
    "      {\n",
    "        \"neurons\": 64,\n",
    "        \"activation\":\"tanh\" \n",
    "      }\n",
    "    ]\n",
    "  ]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(NN,\n",
    "                    param_grid=GRID_DICT,\n",
    "                    scoring=custom_scores,\n",
    "                    refit=\"mee\",\n",
    "                    cv=CV,\n",
    "                    return_train_score=True,\n",
    "                    n_jobs=-1,\n",
    "                    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec gridsearch and fit model\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters: \" + str(grid.best_params_) + \" score: \" + str(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top hyperparameters and results\n",
    "columns = ['mean_fit_time','param_model__lambda_reg', 'param_model__nesterov','param_model__penalty', 'param_model__alpha', 'param_model__lr', 'mean_test_mee', 'std_test_mee']\n",
    "top_models = pd.DataFrame(grid.cv_results_).sort_values(by=['mean_test_mee'], ascending=False)[:3]\n",
    "top_models[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second kfold: validation curves, early stopping and mean error of top models\n",
    "\n",
    "# validation folds\n",
    "val_split = [ test for (train, test) in CV.split(X_train, y_train) ]\n",
    "\n",
    "val_data = [ \n",
    "  (\n",
    "    [X_train.iloc[i].tolist() for i in indexes], \n",
    "    [y_train.iloc[i].tolist() for i in indexes]\n",
    "  ) for indexes in val_split \n",
    "]\n",
    "\n",
    "NN_2 = KRWrapper(\n",
    "  val_data,\n",
    "  5,\n",
    "  callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "      monitor=\"val_loss\", min_delta=0.000001, patience=50, restore_best_weights=True\n",
    "    )\n",
    "  ],\n",
    "  **kerasRegressorParams\n",
    ")\n",
    "\n",
    "grid_dict = { \"scoring\": custom_scores,\n",
    "              \"refit\" : False,\n",
    "              \"cv\" : CV,\n",
    "              \"return_train_score\" : True,\n",
    "              \"n_jobs\" : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec kfold and select the model\n",
    "\n",
    "seed = GRID_DICT['model__seed'][0]\n",
    "\n",
    "n_epochs = []\n",
    "\n",
    "for params in top_models['params']:\n",
    "  print(params)\n",
    "\n",
    "  tr_err, tr_acc, ts_err, ts_acc = [], [], [], []\n",
    "  for i in range(seed, seed+5):\n",
    "    print(\"Seed: \" + str(i))\n",
    "\n",
    "    # reset fold counter and histories\n",
    "    reset_counter()   \n",
    "    clear_histories() \n",
    "\n",
    "    # set params and seed\n",
    "    grid_dict['param_grid'] = { field : [value] for (field, value) in params.items() }\n",
    "    grid_dict['param_grid']['model__seed'] = [i]\n",
    "    grid_2 = GridSearchCV(NN_2, **grid_dict)\n",
    "    grid_2.fit(X_train, y_train)\n",
    "\n",
    "    # save mse and accuracy \n",
    "    tr_err.append( grid_2.cv_results_['mean_train_mee'] ) \n",
    "    ts_err.append( grid_2.cv_results_['mean_test_mee'] ) \n",
    "\n",
    "    # memorize number of epochs (mean over the five folds)\n",
    "    n_epochs.append(mean([ len(get_histories()[i]['loss']) for i in range(5) ]))\n",
    "\n",
    "  print(\"Tr mean mee over 5 inits {:.6f} +/- {:.6f} (std)\\n\" \\\n",
    "        .format( mean(tr_err), std(tr_err) )\n",
    "  )\n",
    "\n",
    "  print(\"Vl mean mee over 5 inits {:.6f} +/- {:.6f} (std)\\n\" \\\n",
    "        .format( mean(ts_err), std(ts_err) )\n",
    "  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain on the development set, compute mean error on the internal test set\n",
    "# and plot learning curve\n",
    "\n",
    "seed = GRID_DICT['model__seed'][0]\n",
    "tr_err, tr_acc, ts_err, ts_acc = [], [], [], []\n",
    "batch_size = kerasRegressorParams['batch_size']\n",
    "\n",
    "# mean test error and std\n",
    "for i in range(seed, seed+5):\n",
    "\n",
    "  NN_params = { field[7:] : value[0] for (field, value) in GRID_DICT.items() }\n",
    "  NN_params['seed'] = i\n",
    "  NN = get_NN(len(X_train.columns), **NN_params)\n",
    "\n",
    "  h = NN.fit(X_train, y_train, batch_size=batch_size, epochs=int(mean(n_epochs)),\\\n",
    "    validation_data=(X_test, y_test), shuffle=True, verbose=0)\n",
    "\n",
    "  # save mee and accuracy\n",
    "  tr_score = NN.evaluate(X_train, y_train, verbose=0)\n",
    "  ts_score = NN.evaluate(X_test, y_test, verbose=0)\n",
    "  tr_err.append( tr_score ) \n",
    "  ts_err.append( ts_score )\n",
    "\n",
    "# compute mee on test set for a single run\n",
    "NN_params['seed'] = seed\n",
    "NN = get_NN(len(X_train.columns), **NN_params)\n",
    "h = NN.fit(X_train, y_train, batch_size=batch_size, epochs=int(mean(n_epochs)),\\\n",
    "    validation_data=(X_test, y_test), shuffle=True, verbose=0)\n",
    "tr_single = NN.evaluate(X_train, y_train, verbose=0)\n",
    "ts_single = NN.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "# print results and plot\n",
    "print(\"Tr. mee on a single run: {:.3f} \\n\".format(tr_single))\n",
    "\n",
    "print(\"Tr. mean mee over 5 inits {:.6f} +/- {:.6f} (std)\\n\".format( mean(tr_err), std(tr_err) ) )\n",
    "\n",
    "print(\"Ts. mee on a single run: {:.3f} \\n\".format(ts_single))\n",
    "\n",
    "print(\"Ts. mean mee over 5 inits {:.6f} +/- {:.6f} (std)\\n\".format( mean(ts_err), std(ts_err) ) )\n",
    "\n",
    "do_NN_plot(h.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write CSV blind test output\n",
    "def write_blind_results(y_pred):\n",
    "\n",
    "  with open(\"3Monkeys_ML-CUP23-TS.csv\", \"w\") as f:\n",
    "    print(\"# Marco Antonio Corallo, Hamza Karoui, Samuele Vezzuto\", file=f)\n",
    "    print(\"# 3Monkeys\", file=f)\n",
    "    print(\"# ML-CUP23\", file=f)\n",
    "    print(\"# 31/01/2024\", file=f)\n",
    "\n",
    "    pred_id = 1\n",
    "    for p in y_pred:\n",
    "      print(\"{},{},{},{}\".format(pred_id, p[0], p[1], p[2]), file=f)\n",
    "      pred_id += 1\n",
    "\n",
    "  f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain also on the test set after the model assessment phase, \n",
    "# in order to learn more before to predict blind test output\n",
    "X, y = pd.concat([X_train, X_test], axis=0), pd.concat([y_train, y_test], axis=0)\n",
    "\n",
    "NN = get_NN(len(X_train.columns), **NN_params)\n",
    "NN.fit(X, y, batch_size=batch_size, epochs=int(mean(n_epochs)), shuffle=True, verbose=0)\n",
    "blind_out = NN.predict(blind_test)\n",
    "write_blind_results(blind_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca81cce83a162b5f4a5d747c8d97a71872a701a68cdc138d0312323614df47fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
