{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "def read_ds(path):\n",
    "  \"\"\"\n",
    "  parse CSV data set and\n",
    "  returns a tuple (input, target)\n",
    "  \"\"\"\n",
    "  df = pd.read_csv(path, sep=\" \", names=['NaN','y','x1','x2','x3','x4','x5','x6','garbage'])\n",
    "  y, df = df['y'], df.drop(columns=['NaN','garbage','y'])\n",
    "  \n",
    "  # One-hot encoding categorical variables\n",
    "  # df = pd.get_dummies(df, columns=['x1','x2','x3','x4','x5','x6']).astype('int')\n",
    "\n",
    "  return (df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets Path\n",
    "TR_PATH = \"./monks/datasets/monks-1.train\"\n",
    "TS_PATH = \"./monks/datasets/monks-1.test\"\n",
    "\n",
    "# read training and test set\n",
    "X_train, y_train = read_ds(TR_PATH)\n",
    "X_test,  y_test  = read_ds(TS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LinearClassifier implements BaseEstimator, in order to reuse the SciKit's Kfold CV\n",
    "class LinearClassifier(BaseEstimator):\n",
    "  def __init__(self, learning_rate=0.01, reg_param=0.1, epochs=1000):\n",
    "    self.learning_rate = learning_rate\n",
    "    self.reg_param = reg_param\n",
    "    self.epochs = epochs\n",
    "    self.poly = None\n",
    "    self.weights = None\n",
    "\n",
    "  # Add bias to the input vector\n",
    "  def add_bias(self, X):\n",
    "    \"\"\" \n",
    "    Adds bias to a vector: [x1, ..., xn] -> [1, x1, ..., xn]\n",
    "    For a matrix, adds a column of ones to the left handside\n",
    "    \"\"\" \n",
    "    return np.c_[np.ones(X.shape[0]), X]\n",
    "\n",
    "  # Polynomial LBE\n",
    "  def to_poly(self, X):\n",
    "    \"\"\"\n",
    "    Take a vector [x1, ..., xn] and returns its polynomial transformation [x1^1, ..., xn^n]\n",
    "    \"\"\"\n",
    "    if self.poly is None:\n",
    "        self.poly = PolynomialFeatures(degree=3)\n",
    "        X_poly = self.poly.fit_transform(X)\n",
    "    else:\n",
    "        X_poly = self.poly.transform(X)\n",
    "    return X_poly\n",
    "    #return np.asarray([ [ X[i][j]**j for j in range(len(X[i])) ] for i in range(len(X)) ])\n",
    "\n",
    "  def fit(self, X, y):\n",
    "    \"\"\"\n",
    "    Fit to the given dataset <X,y>.\n",
    "    It uses the Batch version of gradient descent, with LBE and decremental learning rate\n",
    "    \"\"\"\n",
    "\n",
    "    # Add bias component, apply LBE and set random initial weights vector \n",
    "    X = self.to_poly(self.add_bias(X))\n",
    "    self.weights = np.random.rand(X.shape[1])\n",
    "    dw = np.zeros_like(self.weights)\n",
    "    \n",
    "    # Batch version\n",
    "    for epoch in range(self.epochs):\n",
    "\n",
    "      # Gradient computation\n",
    "      for j in range(len(self.weights)):\n",
    "        s = sum( [ ( y.iloc[p] - np.dot(X[p], self.weights) ) * X[p][j] for p in range(len(X)) ] )\n",
    "        dw[j] = -2/len(X) * s\n",
    "      \n",
    "      # update weights and learning rate\n",
    "      self.weights += self.learning_rate * dw - ( 2 * self.reg_param * self.weights )\n",
    "      self.learning_rate /= 10\n",
    "    return self\n",
    "\n",
    "  def predict(self, X):\n",
    "    \"\"\"\n",
    "    returns the prediction of data X, using fitted weights\n",
    "    \"\"\" \n",
    "    X = self.to_poly(X) # X is without bias!\n",
    "    predictions = X.dot(self.weights[1:]) # x (without beginning 1) * w (without w0)\n",
    "    bias = self.weights[0]\n",
    "    return [ 0 if feature <= bias else 1 for feature in predictions ]\n",
    "    # return np.sign(predictions)\n",
    "\n",
    "  def score(self, X, y):\n",
    "    \"\"\" \n",
    "    computes the prediction of the data X and measures the score wrt target y\n",
    "    \"\"\" \n",
    "    predictions = self.predict(X)\n",
    "    accuracy = np.mean(predictions == y)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold validation\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=7)\n",
    "param_grid = {\n",
    "            'epochs' : [1000],\n",
    "            'learning_rate' : [0.01],\n",
    "            'reg_param' : [0.1]\n",
    "}\n",
    "grid = GridSearchCV(LinearClassifier(), param_grid, cv=cv, n_jobs=-1)\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters: \" + str(grid.best_params_) + \" score: \" + str(grid.best_score_))\n",
    "\n",
    "lc = grid.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation confusion matrix\n",
    "lc = grid.best_estimator_\n",
    "predictions = lc.predict(X_train)\n",
    "cm = confusion_matrix(y_train, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()\n",
    "\n",
    "# Model assessment\n",
    "\n",
    "lc.score(X_test, y_test)\n",
    "predictions = lc.predict(X_test)\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca81cce83a162b5f4a5d747c8d97a71872a701a68cdc138d0312323614df47fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
