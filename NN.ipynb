{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "import metrics as mt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets Path\n",
    "TR_PATH = \"./monks/datasets/monks-1.train\"\n",
    "TS_PATH = \"./monks/datasets/monks-1.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class ThreeLayerNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(ThreeLayerNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.layer2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.layer3 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        x = self.layer1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.layer2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = self.layer3(x)\n",
    "        x = self.sigmoid(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ds(path):\n",
    "  \"\"\"\n",
    "  parse CSV data set and\n",
    "  returns a tuple (input, target)\n",
    "  \"\"\"\n",
    "  df = pd.read_csv(path, sep=\" \", names=['NaN','y','x1','x2','x3','x4','x5','x6','garbage'])\n",
    "  y, df = df['y'], df.drop(columns=['NaN','garbage','y'])\n",
    "  \n",
    "  # One-hot encoding categorical variables\n",
    "  df = pd.get_dummies(df, columns=['x1','x2','x3','x4','x5','x6']).astype('int')\n",
    "\n",
    "  return (df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read training and test set\n",
    "train_data, train_labels = read_ds(TR_PATH)\n",
    "val_data,  val_labels  = read_ds(TS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = torch.tensor(train_data.values).float()\n",
    "train_labels = torch.tensor(train_labels.values).float()\n",
    "\n",
    "val_data = torch.tensor(val_data.values).float()\n",
    "val_labels = torch.tensor(val_labels.values).float()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hidden size: 30, Learning rate: 0.1, Validation loss: 0.012192058376967907\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import torch.optim as optim\n",
    "\n",
    "hidden_sizes = [10, 20, 30]\n",
    "learning_rates = [0.001, 0.01, 0.1]\n",
    "epochs = 1000\n",
    "input_size = len(val_data[0])\n",
    "output_size = 1\n",
    "\n",
    "best_params = None\n",
    "\n",
    "for hidden_size, learning_rate in product(hidden_sizes, learning_rates):\n",
    "\n",
    "    net = ThreeLayerNN(input_size, hidden_size, output_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=learning_rate)\n",
    "    for epoch in range(epochs) :\n",
    "        # Forward pass\n",
    "        outputs = net(train_data).view(-1)\n",
    "        # Compute the training loss\n",
    "        loss = criterion(outputs, train_labels)\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Evaluate on the validation set\n",
    "    with torch.no_grad():\n",
    "        val_outputs = net(val_data).view(-1)\n",
    "        val_loss = criterion (val_outputs, val_labels)\n",
    "\n",
    "    if best_params is None or val_loss < best_params[0]:\n",
    "        best_params = (val_loss, hidden_size, learning_rate)\n",
    "\n",
    "print(f\"Best Hidden size: {hidden_size}, Learning rate: {learning_rate}, Validation loss: {val_loss}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
