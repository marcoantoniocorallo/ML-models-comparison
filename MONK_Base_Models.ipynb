{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from monk_helpers import CV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ds(path):\n",
    "  \"\"\"\n",
    "  parse CSV data set and\n",
    "  returns a tuple (input, target)\n",
    "  \"\"\"\n",
    "  df = pd.read_csv(path, sep=\" \", names=['NaN','y','x1','x2','x3','x4','x5','x6','garbage'])\n",
    "  y, df = df['y'], df.drop(columns=['NaN','garbage','y'])\n",
    "  \n",
    "  # One-hot encoding categorical variables\n",
    "  df = pd.get_dummies(df, columns=['x1','x2','x3','x4','x5','x6']).astype('int')\n",
    "\n",
    "  return (df, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets Path\n",
    "TR_PATH_1 = \"./monks/datasets/monks-1.train\"\n",
    "TS_PATH_1 = \"./monks/datasets/monks-1.test\"\n",
    "# Datasets Path\n",
    "TR_PATH_2 = \"./monks/datasets/monks-2.train\"\n",
    "TS_PATH_2 = \"./monks/datasets/monks-2.test\"\n",
    "# Datasets Path\n",
    "TR_PATH_3 = \"./monks/datasets/monks-3.train\"\n",
    "TS_PATH_3 = \"./monks/datasets/monks-3.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "cv_strategy = CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function extracting each grid from dictionary of grids\n",
    "def list_grids(grids_dict):\n",
    "    return [grids_dict[item] for item in grids_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that prints the classification report\n",
    "def print_report_score(test_label, test_pred):\n",
    "    mse = mean_squared_error(test_label, test_pred)\n",
    "    print(\"MSE: \", mse)\n",
    "    print(classification_report(test_label, \n",
    "                            test_pred, \n",
    "                            target_names=['0', '1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_GAUSSIAN_NB = { 'var_smoothing': np.logspace(0,-9, num=100) }\n",
    "GRID_BERNULLI_NB = { 'alpha': np.linspace(0,1, num=100), \"force_alpha\":[True] }\n",
    "GRID_KNN = { \n",
    "            'n_neighbors' : range(1,25), \n",
    "            'algorithm' : ['auto', 'ball_tree', 'kd_tree', 'brute'], \n",
    "            'metric' : ['euclidean', 'manhattan', 'chebyshev', 'minkowski'], \n",
    "            'weights' : ['distance', 'uniform'] \n",
    "            }\n",
    "GRID_MNB = {  }\n",
    "\n",
    "GRID_SVM = {\n",
    "  \"linear_rbf_sigmoid\": {\n",
    "   \"kernel\": ['linear', 'rbf','sigmoid'],\n",
    "   \"C\":[0.01,10,100],\n",
    "   \"gamma\" : ['scale', 'auto']\n",
    "  },\n",
    "  \"poly\": {\n",
    "    \"kernel\": ['poly'],\n",
    "    \"C\":[0.01,10,100],\n",
    "    \"degree\": [2,3,5],\n",
    "    \"gamma\" : ['scale', 'auto']\n",
    "  }\n",
    "    } \n",
    "GRID_LGREG = { \n",
    "    \"lbfgs_newton-cg_newton-cholesky_sag\": {\n",
    "    \"penalty\": ['l2', None],\n",
    "    \"fit_intercept\":[True,False],\n",
    "    \"class_weight\":[{0:0.6,1:0.4},\"balanced\"],\n",
    "    \"solver\":['lbfgs', 'newton-cg', 'newton-cholesky', 'sag'],\n",
    "    },\n",
    "    \"liblinear\":{\n",
    "    \"penalty\": ['l1', 'l2'],\n",
    "    \"fit_intercept\":[True,False],\n",
    "    \"class_weight\":[{0:0.6,1:0.4},\"balanced\"],\n",
    "    \"solver\":['liblinear'],\n",
    "    },\n",
    "    \"saga\":{\n",
    "    \"penalty\": ['l1', 'l2','elasticnet',None],\n",
    "    \"l1_ratio\":[0.5,0.6,0.7,0.3],\n",
    "    \"fit_intercept\":[True,False],\n",
    "    \"class_weight\":[{0:0.6,1:0.4},\"balanced\"],\n",
    "    \"solver\":['saga'],\n",
    "    }\n",
    " }\n",
    "\n",
    "GRID_DT = {\n",
    "        'criterion': ['gini', 'entropy','log_loss'],\n",
    "        'max_depth': [5,10,None],\n",
    "        'max_features': ['sqrt', 'log2', None],\n",
    "        'min_samples_split': [2,4,8,16],\n",
    "        'min_samples_leaf': [1,2,4,8]\n",
    "        }\n",
    "        \n",
    "#Ensemble methods:\n",
    "GRID_RF = {\n",
    "    'max_depth': [5, 15, None],\n",
    "    'max_features': ['log2', None],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'n_estimators': [32, 64, 128],\n",
    "    \"bootstrap\": [True, False],\n",
    "    \"criterion\": [\"entropy\", \"gini\", \"log_loss\"]\n",
    "    }\n",
    "\n",
    "params_map = {\n",
    "    'gaussian_nb': GRID_GAUSSIAN_NB,\n",
    "    'bernulli_nb': GRID_BERNULLI_NB,\n",
    "    'multinomial_nb': GRID_MNB,\n",
    "    'knn': GRID_KNN,\n",
    "    \"svm\": GRID_SVM,\n",
    "    \"logistic_regression\":GRID_LGREG,\n",
    "    \"decision_tree\":GRID_DT,\n",
    "    \"random_forest\":GRID_RF\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_gridesearch(X, y, model, model_name):\n",
    "  params = params_map[model_name]\n",
    "  if((model_name == \"logistic_regression\") or (model_name == \"svm\")):\n",
    "    params = list_grids(params)\n",
    "  grid = GridSearchCV(model, params,scoring=\"accuracy\",refit=True, cv=cv_strategy, n_jobs=-1,verbose=10).fit(X, y)\n",
    "  results = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "  print(\"Mean validation accuracy: \", results[\"mean_test_score\"][grid.best_index_])\n",
    "\n",
    "  print(\"Mean validation accuracy: \", results[\"mean_test_score\"][grid.best_index_])\n",
    "  print(\"Mean std validation accuracy: \", results[\"std_test_score\"][grid.best_index_])\n",
    "  return grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that prints the confusion matrix\n",
    "def print_confusion_matrix(test_label, pred_label):\n",
    "    cm = confusion_matrix(test_label, pred_label)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"0\",\"1\"])\n",
    "    disp.plot()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def do_sklearn_GridSearchCV(X,y,X_test,y_test,model,model_name,i):\n",
    "    print(\"Model Used: \" + model_name + \" On monk: \",i)\n",
    "    grid = execute_gridesearch(X, y, model, model_name)\n",
    "    print(\"Model used: \" + model_name + \", best parameters: \" + str(grid.best_params_) )\n",
    "    y_pred = grid.best_estimator_.predict(X_test)\n",
    "    print(\"accuracy on test set {:.3f}\".format(accuracy_score(y_test,y_pred)))\n",
    "    print_report_score(y_test,y_pred)\n",
    "    print_confusion_matrix(y_test,y_pred)\n",
    "    print(\"------------------------------------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_model(model,model_name):\n",
    "    for i in range(0,3):\n",
    "        if i == 0:\n",
    "            X_train, y_train = read_ds(TR_PATH_1)\n",
    "            X_test, y_test = read_ds(TS_PATH_1)\n",
    "        elif i == 1:\n",
    "            X_train, y_train = read_ds(TR_PATH_2)\n",
    "            X_test, y_test = read_ds(TS_PATH_2)\n",
    "        elif i == 2:\n",
    "            X_train, y_train = read_ds(TR_PATH_3)\n",
    "            X_test, y_test = read_ds(TS_PATH_3)\n",
    "        grid_svm = do_sklearn_GridSearchCV(X_train,y_train,X_test,y_test,model,model_name,i+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model(LogisticRegression(),\"logistic_regression\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model(GaussianNB(),\"gaussian_nb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model(BernoulliNB(),\"bernulli_nb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model(MultinomialNB(),\"multinomial_nb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model(KNeighborsClassifier(),\"knn\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model(SVC(),\"svm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model(DecisionTreeClassifier(),\"decision_tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_model(RandomForestClassifier(),\"random_forest\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
