{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monk benchmark: Keras NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python modules:\n",
    "- Numpy v1.26.2\n",
    "- Pandas v2.1.4\n",
    "- Matplotlib v3.8.2\n",
    "- Keras v2.15.0:            `pip install --upgrade keras`\n",
    "- Tensorflow v2.15.0.post1: `pip install --upgrade tensorflow`\n",
    "- SciKeras v0.12.0:         `pip install scikeras`\n",
    "- SciKit-Learn v1.3.2:      `pip install --upgrade scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress debugging information about GPU\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "\n",
    "import os.path\n",
    "import sys\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy import mean, std\n",
    "from keras.initializers import RandomUniform, GlorotUniform, Zeros\n",
    "from keras.layers import Dense, InputLayer\n",
    "from keras.losses import MeanSquaredError\n",
    "from keras.metrics import BinaryAccuracy\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import *\n",
    "from keras.regularizers import L2, L1\n",
    "from keras.callbacks import Callback\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from pathlib import Path\n",
    "from monk_helpers import *\n",
    "\n",
    "# set random seed for reproducible experiments\n",
    "tf.random.set_seed(42)\n",
    "keras.utils.set_random_seed(42)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_NN: Function that builds up a NN\n",
    "def get_NN(X_len, initializer=\"random\", seed=42, neurons=4, lr=0.01, alpha=0.5,\n",
    "          hidden_activation=\"tanh\", lambda_reg=None, penalty=None, nesterov=False):\n",
    "\n",
    "  # weight initialization\n",
    "  init, bias = (GlorotUniform(seed=seed), Zeros())  if initializer==\"glorot\" \\\n",
    "          else (RandomUniform(seed=seed), RandomUniform(seed=seed))\n",
    "\n",
    "  # regularization\n",
    "  regularizer = L1(l1=lambda_reg) if penalty == \"L1\" \\\n",
    "          else  L2(l2=lambda_reg) if penalty == \"L2\" \\\n",
    "          else  None\n",
    "\n",
    "  # 1 hidden layer\n",
    "  NN_model = Sequential()\n",
    "  NN_model.add(InputLayer(input_shape=(X_len,)))\n",
    "  NN_model.add(Dense(units=neurons,  activation=hidden_activation, kernel_initializer=init, \n",
    "                bias_initializer=bias, kernel_regularizer=regularizer)\n",
    "              )\n",
    "  NN_model.add(Dense(units=1, activation=\"sigmoid\", kernel_initializer=init, \n",
    "                bias_initializer=bias, kernel_regularizer=regularizer)\n",
    "              )\n",
    "\n",
    "  NN_model.compile(\n",
    "    optimizer=SGD( \n",
    "      learning_rate=lr, momentum=alpha, nesterov=nesterov\n",
    "    ), loss=MeanSquaredError(), metrics=BinaryAccuracy()\n",
    "  )\n",
    "  \n",
    "  return NN_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities to get the mean of K histories\n",
    "\n",
    "def add_padding(ls, n):\n",
    "  ls.extend([ls[-1]] * n)\n",
    "  return ls\n",
    "\n",
    "def longest(ls):\n",
    "  return len(max(ls, key=(lambda history : len(history['loss'])))['loss'])\n",
    "\n",
    "def mean_epochs(l):\n",
    "  return int(mean([ len(item['loss']) for item in l ]))\n",
    "\n",
    "def mean_history(_histories):\n",
    "  m = mean_epochs(_histories)+1\n",
    "  # m = longest(_histories)\n",
    "  for history in _histories:\n",
    "    l = len(history['loss'])\n",
    "    for field in _histories[0]:\n",
    "      if l>= m:\n",
    "        history[field] = history[field][:m]\n",
    "      else:\n",
    "        history[field] = add_padding(history[field], (m-l))\n",
    "  return \\\n",
    "    { field : \n",
    "        [ \n",
    "          (sum(x)/len(_histories)) for x in zip(\n",
    "            *[ history[field] for history in _histories ]\n",
    "          )\n",
    "        ] for field in _histories[0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static fold counter\n",
    "def count():\n",
    "  count.count += 1\n",
    "  return count.count\n",
    "\n",
    "def reset_counter():\n",
    "  count.count =-1\n",
    "\n",
    "def get_count():\n",
    "  return count.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static history register\n",
    "def histories():\n",
    "  histories.histories = []\n",
    "\n",
    "def register(h):\n",
    "  histories.histories.append(h)\n",
    "\n",
    "def get_histories():\n",
    "  return histories.histories\n",
    "\n",
    "def clear_histories():\n",
    "  histories()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot utility\n",
    "def do_NN_plot(history):\n",
    "\n",
    "  # Plot Accuracy\n",
    "  plt.plot(history['binary_accuracy'])\n",
    "  plt.plot(history['val_binary_accuracy'], linestyle=\"--\", color=\"orange\")\n",
    "  plt.title(f'model accuracy')\n",
    "  plt.ylabel('accuracy')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['training', 'test'], loc='lower right')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot loss\n",
    "  plt.plot(history['loss'])\n",
    "  plt.plot(history['val_loss'],  linestyle=\"--\", color=\"orange\")\n",
    "  plt.title(f'model MSE')\n",
    "  plt.ylabel('MSE')\n",
    "  plt.xlabel('epoch')\n",
    "  plt.legend(['training', 'test'], loc='upper right')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KerasClassifier Wrapper for kfold\n",
    "class KCWrapper(KerasClassifier):\n",
    "\n",
    "  def __init__(self, val_data, k, *args, **kwargs):\n",
    "    super(KCWrapper, self).__init__(*args, **kwargs)\n",
    "    self.val_data = val_data\n",
    "    self.k = k\n",
    "    \n",
    "  def fit(self, X, y, **kwargs):\n",
    "    h = super().fit(X, y, validation_data=self.val_data[count()], **kwargs)\n",
    "    register(h.history_)\n",
    "    # do_NN_plot(h.history_)  # plot single fold curve\n",
    "    if self.kfold_finished(): # plot mean of k folds curves\n",
    "      do_NN_plot(mean_history(get_histories()))\n",
    "    \n",
    "  def kfold_finished(self):\n",
    "    return self.k == get_count()+1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monk 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets Path\n",
    "TR_PATH = \"./monks/datasets/monks-1.train\"\n",
    "TS_PATH = \"./monks/datasets/monks-1.test\"\n",
    "\n",
    "X_train, y_train = read_ds(TR_PATH)\n",
    "X_test, y_test = read_ds(TS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grids for gridsearchcv\n",
    "kerasClassifierParams = {\n",
    "  \"model\" : get_NN,\n",
    "  \"X_len\" : len(X_train.columns),\n",
    "  \"loss\" : \"mse\",\n",
    "  \"optimizer\" : \"SGD\", # fixed into get_NN\n",
    "  \"epochs\" : 300,\n",
    "  \"batch_size\" : 4,\n",
    "  \"shuffle\" : True,\n",
    "  \"verbose\" : False\n",
    "}\n",
    "\n",
    "NN = KerasClassifier(**kerasClassifierParams)\n",
    "\n",
    "custom_scores_monk = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"mse\": make_scorer(mean_squared_error,greater_is_better=False)\n",
    "}\n",
    "\n",
    "NN_MONK1_GRID_DICT = {\n",
    "  # \"epochs\" : [100, 300, 600],\n",
    "  # \"batch_size\" : [4, 10, 16, 32, 64],\n",
    "  \"model__lr\" : [0.25], # [0.01, 0.2, 0.22, 0.25, 0.3, 0.4, 0.5]\n",
    "  \"model__alpha\" : [0.8], # [0.5, 0.55, 0.6, 0.62, 0.7, 0.79, 0.8, 0.81, 0.9]\n",
    "  \"model__hidden_activation\" : [\"tanh\"],\n",
    "  \"model__neurons\" : [4], # [2, 3, 4]\n",
    "  \"model__initializer\" : [\"glorot\"], # [\"random\", \"glorot\"]\n",
    "  \"model__nesterov\" : [True], # [True, False]\n",
    "  \"model__penalty\": [None], # [None, \"L1\", \"L2\"],\n",
    "  \"model__lambda_reg\": [None], # [0.01, 0.005]\n",
    "  \"model__seed\" : [15]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(NN,\n",
    "                    param_grid=NN_MONK1_GRID_DICT,\n",
    "                    scoring=custom_scores_monk,\n",
    "                    refit=\"mse\",\n",
    "                    cv=CV,\n",
    "                    return_train_score=True,\n",
    "                    n_jobs=-1,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec gridsearch and fit model\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters: \" + str(grid.best_params_) + \" score: \" + str(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top hyperparameters and results\n",
    "columns = ['rank_test_accuracy', 'param_model__nesterov', 'param_model__alpha', 'param_model__lr', 'mean_test_mse', 'std_test_mse', 'mean_fit_time']\n",
    "top_models = pd.DataFrame(grid.cv_results_).sort_values(by=['rank_test_accuracy','mean_fit_time']).query('rank_test_accuracy<=3')\n",
    "top_models[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second kfold: validation curves, early stopping and mean error of top models\n",
    "\n",
    "# validation folds\n",
    "val_split = [ test for (train, test) in CV.split(X_train, y_train) ]\n",
    "\n",
    "val_data = [ \n",
    "  (\n",
    "    [X_train.iloc[i].tolist() for i in indexes], \n",
    "    [y_train.iloc[i].tolist() for i in indexes]\n",
    "  ) for indexes in val_split \n",
    "]\n",
    "\n",
    "NN_2 = KCWrapper(\n",
    "  val_data,\n",
    "  5,\n",
    "  callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "      monitor=\"val_loss\", min_delta=0.0001, patience=20, restore_best_weights=True\n",
    "    )\n",
    "  ],\n",
    "  **kerasClassifierParams\n",
    ")\n",
    "\n",
    "grid_dict = { \"scoring\": custom_scores_monk,\n",
    "              \"refit\" : False,\n",
    "              \"cv\" : CV,\n",
    "              \"return_train_score\" : True,\n",
    "              \"n_jobs\" : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec kfold and select the model\n",
    "\n",
    "seed = NN_MONK1_GRID_DICT['model__seed'][0]\n",
    "\n",
    "n_epochs = []\n",
    "\n",
    "for params in top_models['params']:\n",
    "  print(params)\n",
    "\n",
    "  tr_err, tr_acc, ts_err, ts_acc = [], [], [], []\n",
    "  for i in range(seed, seed+5):\n",
    "    print(\"Seed: \" + str(i))\n",
    "\n",
    "    # reset fold counter and histories\n",
    "    reset_counter()   \n",
    "    clear_histories() \n",
    "\n",
    "    # set params and seed\n",
    "    grid_dict['param_grid'] = { field : [value] for (field, value) in params.items() }\n",
    "    grid_dict['param_grid']['model__seed'] = [i]\n",
    "    grid_2 = GridSearchCV(NN_2, **grid_dict)\n",
    "    grid_2.fit(X_train, y_train)\n",
    "\n",
    "    # save mse and accuracy \n",
    "    tr_err.append( grid_2.cv_results_['mean_train_mse'] ) \n",
    "    tr_acc.append( grid_2.cv_results_['mean_train_accuracy'] )\n",
    "    ts_err.append( grid_2.cv_results_['mean_test_mse'] ) \n",
    "    ts_acc.append( grid_2.cv_results_['mean_test_accuracy'] )\n",
    "\n",
    "    # memorize number of epochs (mean over the five folds)\n",
    "    n_epochs.append(mean([ len(get_histories()[i]['loss']) for i in range(5) ]))\n",
    "\n",
    "  print(\"Tr mean accuracy over 5 inits: {:.3f} +/- {:.3f} (std)\\nTr mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\" \\\n",
    "        .format(\n",
    "          mean(tr_acc), std(tr_acc),\n",
    "          mean(tr_err), std(tr_err)\n",
    "        )\n",
    "  )\n",
    "\n",
    "  print(\"Vl mean accuracy over 5 inits: {:.3f} +/- {:.3f} (std)\\nVl mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\" \\\n",
    "        .format(\n",
    "          mean(ts_acc), std(ts_acc),\n",
    "          mean(ts_err), std(ts_err)\n",
    "        )\n",
    "  ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain on the whole ds, compute accuracy, mean test error and plot learning curve\n",
    "\n",
    "seed = NN_MONK1_GRID_DICT['model__seed'][0]\n",
    "tr_err, tr_acc, ts_err, ts_acc = [], [], [], []\n",
    "batch_size = kerasClassifierParams['batch_size']\n",
    "\n",
    "# mean test error and std\n",
    "for i in range(seed, seed+5):\n",
    "\n",
    "  NN_monk1_params = { field[7:] : value[0] for (field, value) in NN_MONK1_GRID_DICT.items() }\n",
    "  NN_monk1_params['seed'] = i\n",
    "  NN_monk1 = get_NN(len(X_train.columns), **NN_monk1_params)\n",
    "\n",
    "  h = NN_monk1.fit(X_train, y_train, batch_size=batch_size, epochs=int(mean(n_epochs)),\\\n",
    "    validation_data=(X_test, y_test), shuffle=True, verbose=0)\n",
    "\n",
    "  # save mse and accuracy\n",
    "  tr_score = NN_monk1.evaluate(X_train, y_train, verbose=0)\n",
    "  ts_score = NN_monk1.evaluate(X_test, y_test, verbose=0)\n",
    "  tr_err.append( tr_score[0] ) \n",
    "  ts_err.append( ts_score[0] )\n",
    "\n",
    "# compute accuracy on test set\n",
    "NN_monk1_params['seed'] = seed\n",
    "NN_monk1 = get_NN(len(X_train.columns), **NN_monk1_params)\n",
    "h = NN_monk1.fit(X_train, y_train, batch_size=batch_size, epochs=int(mean(n_epochs)),\\\n",
    "    validation_data=(X_test, y_test), shuffle=True, verbose=0)\n",
    "tr_accuracy = NN_monk1.evaluate(X_train, y_train, verbose=0)[1]\n",
    "ts_accuracy = NN_monk1.evaluate(X_test, y_test, verbose=0)[1]\n",
    "\n",
    "# print results and plot\n",
    "print(\"Tr. accuracy: {:.3f} \\n\".format(tr_accuracy))\n",
    "\n",
    "print(\"Tr. mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\".format( mean(tr_err), std(tr_err) ) )\n",
    "\n",
    "print(\"Ts. accuracy: {:.3f} \\n\".format(ts_accuracy))\n",
    "\n",
    "print(\"Ts. mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\".format( mean(ts_err), std(ts_err) ) )\n",
    "\n",
    "do_NN_plot(h.history)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monk 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets Path\n",
    "TR_PATH = \"./monks/datasets/monks-2.train\"\n",
    "TS_PATH = \"./monks/datasets/monks-2.test\"\n",
    "\n",
    "X_train, y_train = read_ds(TR_PATH)\n",
    "X_test, y_test = read_ds(TS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grids for gridsearchcv\n",
    "kerasClassifierParams = {\n",
    "  \"model\" : get_NN,\n",
    "  \"X_len\" : len(X_train.columns),\n",
    "  \"loss\" : \"mse\",\n",
    "  \"optimizer\" : \"SGD\", # fixed into get_NN\n",
    "  \"epochs\" : 300,\n",
    "  \"batch_size\" : 4,\n",
    "  \"shuffle\" : True,\n",
    "  \"verbose\" : False\n",
    "}\n",
    "\n",
    "NN = KerasClassifier(**kerasClassifierParams)\n",
    "\n",
    "custom_scores_monk = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"mse\": make_scorer(mean_squared_error,greater_is_better=False)\n",
    "}\n",
    "\n",
    "NN_MONK2_GRID_DICT = {\n",
    "  # \"epochs\" : [100, 300, 600],\n",
    "  # \"batch_size\" : [4, 10, 16, 32, 64],\n",
    "  \"model__lr\" : [0.25], # [0.01, 0.2, 0.22, 0.25, 0.3, 0.4, 0.5]\n",
    "  \"model__alpha\" : [0.8], # [0.5, 0.55, 0.6, 0.62, 0.7, 0.79, 0.8, 0.81, 0.9]\n",
    "  \"model__hidden_activation\" : [\"tanh\"],\n",
    "  \"model__neurons\" : [4], # [2, 3, 4]\n",
    "  \"model__initializer\" : [\"glorot\"], # [\"random\", \"glorot\"]\n",
    "  \"model__nesterov\" : [True], # [True, False]\n",
    "  \"model__penalty\": [None], # [None, \"L1\", \"L2\"],\n",
    "  \"model__lambda_reg\": [None], # [0.01, 0.005]\n",
    "  \"model__seed\" : [15]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(NN,\n",
    "                    param_grid=NN_MONK2_GRID_DICT,\n",
    "                    scoring=custom_scores_monk,\n",
    "                    refit=\"mse\",\n",
    "                    cv=CV,\n",
    "                    return_train_score=True,\n",
    "                    n_jobs=-1,\n",
    "                    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec gridsearch and fit model\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters: \" + str(grid.best_params_) + \" score: \" + str(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top hyperparameters and results\n",
    "columns = ['rank_test_accuracy', 'param_model__nesterov', 'param_model__alpha', 'param_model__lr', 'mean_test_mse', 'std_test_mse', 'mean_fit_time']\n",
    "top_models = pd.DataFrame(grid.cv_results_).sort_values(by=['rank_test_accuracy','mean_fit_time']).query('rank_test_accuracy<=3')\n",
    "top_models[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second kfold: validation curves, early stopping and mean error of top models\n",
    "\n",
    "# validation folds\n",
    "val_split = [ test for (train, test) in CV.split(X_train, y_train) ]\n",
    "\n",
    "val_data = [ \n",
    "  (\n",
    "    [X_train.iloc[i].tolist() for i in indexes], \n",
    "    [y_train.iloc[i].tolist() for i in indexes]\n",
    "  ) for indexes in val_split \n",
    "]\n",
    "\n",
    "NN_2 = KCWrapper(\n",
    "  val_data,\n",
    "  5,\n",
    "  callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "      monitor=\"val_loss\", min_delta=0.0001, patience=20, restore_best_weights=True\n",
    "    )\n",
    "  ],\n",
    "  **kerasClassifierParams\n",
    ")\n",
    "\n",
    "grid_dict = { \"scoring\": custom_scores_monk,\n",
    "              \"refit\" : False,\n",
    "              \"cv\" : CV,\n",
    "              \"return_train_score\" : True,\n",
    "              \"n_jobs\" : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec kfold and select the model\n",
    "\n",
    "seed = NN_MONK2_GRID_DICT['model__seed'][0]\n",
    "\n",
    "n_epochs = []\n",
    "\n",
    "for params in top_models['params']:\n",
    "  print(params)\n",
    "\n",
    "  tr_err, tr_acc, ts_err, ts_acc = [], [], [], []\n",
    "  for i in range(seed, seed+5):\n",
    "    print(\"Seed: \" + str(i))\n",
    "\n",
    "    # reset fold counter and histories\n",
    "    reset_counter()   \n",
    "    clear_histories() \n",
    "\n",
    "    # set params and seed\n",
    "    grid_dict['param_grid'] = { field : [value] for (field, value) in params.items() }\n",
    "    grid_dict['param_grid']['model__seed'] = [i]\n",
    "    grid_2 = GridSearchCV(NN_2, **grid_dict)\n",
    "    grid_2.fit(X_train, y_train)\n",
    "\n",
    "    # save mse and accuracy \n",
    "    tr_err.append( grid_2.cv_results_['mean_train_mse'] ) \n",
    "    tr_acc.append( grid_2.cv_results_['mean_train_accuracy'] )\n",
    "    ts_err.append( grid_2.cv_results_['mean_test_mse'] ) \n",
    "    ts_acc.append( grid_2.cv_results_['mean_test_accuracy'] )\n",
    "\n",
    "    # memorize number of epochs (mean over the five folds)\n",
    "    n_epochs.append(mean([ len(get_histories()[i]['loss']) for i in range(5) ]))\n",
    "\n",
    "  print(\"Tr mean accuracy over 5 inits: {:.3f} +/- {:.3f} (std)\\nTr mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\" \\\n",
    "        .format(\n",
    "          mean(tr_acc), std(tr_acc),\n",
    "          mean(tr_err), std(tr_err)\n",
    "        )\n",
    "  )\n",
    "\n",
    "  print(\"Vl mean accuracy over 5 inits: {:.3f} +/- {:.3f} (std)\\nVl mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\" \\\n",
    "        .format(\n",
    "          mean(ts_acc), std(ts_acc),\n",
    "          mean(ts_err), std(ts_err)\n",
    "        )\n",
    "  ) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain on the whole ds, compute accuracy, mean test error and plot learning curve\n",
    "\n",
    "seed = NN_MONK2_GRID_DICT['model__seed'][0]\n",
    "tr_err, tr_acc, ts_err, ts_acc = [], [], [], []\n",
    "batch_size = kerasClassifierParams['batch_size']\n",
    "\n",
    "# mean test error and std\n",
    "for i in range(seed, seed+5):\n",
    "\n",
    "  NN_monk2_params = { field[7:] : value[0] for (field, value) in NN_MONK2_GRID_DICT.items() }\n",
    "  NN_monk2_params['seed'] = i\n",
    "  NN_monk2 = get_NN(len(X_train.columns), **NN_monk2_params)\n",
    "\n",
    "  h = NN_monk2.fit(X_train, y_train, batch_size=batch_size, epochs=int(mean(n_epochs)),\\\n",
    "    validation_data=(X_test, y_test), shuffle=True, verbose=0)\n",
    "\n",
    "  # save mse and accuracy\n",
    "  tr_score = NN_monk2.evaluate(X_train, y_train, verbose=0)\n",
    "  ts_score = NN_monk2.evaluate(X_test, y_test, verbose=0)\n",
    "  tr_err.append( tr_score[0] ) \n",
    "  ts_err.append( ts_score[0] )\n",
    "\n",
    "# compute accuracy on test set\n",
    "NN_monk2_params['seed'] = seed\n",
    "NN_monk2 = get_NN(len(X_train.columns), **NN_monk2_params)\n",
    "h = NN_monk2.fit(X_train, y_train, batch_size=batch_size, epochs=int(mean(n_epochs)),\\\n",
    "    validation_data=(X_test, y_test), shuffle=True, verbose=0)\n",
    "tr_accuracy = NN_monk2.evaluate(X_train, y_train, verbose=0)[1]\n",
    "ts_accuracy = NN_monk2.evaluate(X_test, y_test, verbose=0)[1]\n",
    "\n",
    "# print results and plot\n",
    "print(\"Tr. accuracy: {:.3f} \\n\".format(tr_accuracy))\n",
    "\n",
    "print(\"Tr. mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\".format( mean(tr_err), std(tr_err) ) )\n",
    "\n",
    "print(\"Ts. accuracy: {:.3f} \\n\".format(ts_accuracy))\n",
    "\n",
    "print(\"Ts. mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\".format( mean(ts_err), std(ts_err) ) )\n",
    "\n",
    "do_NN_plot(h.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monk 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets Path\n",
    "TR_PATH = \"./monks/datasets/monks-3.train\"\n",
    "TS_PATH = \"./monks/datasets/monks-3.test\"\n",
    "\n",
    "X_train, y_train = read_ds(TR_PATH)\n",
    "X_test, y_test = read_ds(TS_PATH)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define grids for gridsearchcv\n",
    "kerasClassifierParams = {\n",
    "  \"model\" : get_NN,\n",
    "  \"X_len\" : len(X_train.columns),\n",
    "  \"loss\" : \"mse\",\n",
    "  \"optimizer\" : \"SGD\", # fixed into get_NN\n",
    "  \"epochs\" : 300,\n",
    "  \"batch_size\" : 32,\n",
    "  \"shuffle\" : True,\n",
    "  \"verbose\" : False\n",
    "}\n",
    "\n",
    "NN = KerasClassifier(**kerasClassifierParams)\n",
    "\n",
    "custom_scores_monk = {\n",
    "    \"accuracy\": \"accuracy\",\n",
    "    \"mse\": make_scorer(mean_squared_error,greater_is_better=False)\n",
    "}\n",
    "\n",
    "NN_MONK3_GRID_DICT = {\n",
    "  # \"epochs\" : [100, 300, 600],\n",
    "  # \"batch_size\" : #[4, 8, 16, 32, 64],\n",
    "  \"model__lr\" : [0.02], # [0.01, 0.02, 0.05, 0.2]\n",
    "  \"model__alpha\" : [0.69], # [0.5, 0.55, 0.6, 0.65, 0.7, 0.8]\n",
    "  \"model__hidden_activation\" : [\"tanh\"],\n",
    "  \"model__neurons\" : [4], # [2, 3, 4]\n",
    "  \"model__initializer\" : [\"glorot\"], # [\"random\", \"glorot\"]\n",
    "  \"model__nesterov\" : [True], # [True, False]\n",
    "  \"model__penalty\": [\"L1\"], # [\"L1\", \"L2\"],\n",
    "  \"model__lambda_reg\": [0.002], # [0.01, 0.005]\n",
    "  \"model__seed\" : [15]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(NN,\n",
    "                    param_grid=NN_MONK3_GRID_DICT,\n",
    "                    scoring=custom_scores_monk,\n",
    "                    refit=\"mse\",\n",
    "                    cv=CV,\n",
    "                    return_train_score=True,\n",
    "                    n_jobs=-1,\n",
    "                    \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec gridsearch and fit model\n",
    "grid.fit(X_train, y_train)\n",
    "print(\"Best parameters: \" + str(grid.best_params_) + \" score: \" + str(grid.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print top hyperparameters and results\n",
    "columns = ['rank_test_accuracy', 'param_model__penalty', 'param_model__lambda_reg', 'param_model__nesterov', 'param_model__alpha', 'param_model__lr', 'mean_test_mse', 'std_test_mse', 'mean_fit_time']\n",
    "top_models = pd.DataFrame(grid.cv_results_).sort_values(by=['rank_test_accuracy','mean_fit_time']).query('rank_test_accuracy<=3')\n",
    "top_models[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second kfold: validation curves, early stopping and mean error of top models\n",
    "\n",
    "# validation folds\n",
    "val_split = [ test for (train, test) in CV.split(X_train, y_train) ]\n",
    "\n",
    "val_data = [ \n",
    "  (\n",
    "    [X_train.iloc[i].tolist() for i in indexes], \n",
    "    [y_train.iloc[i].tolist() for i in indexes]\n",
    "  ) for indexes in val_split \n",
    "]\n",
    "\n",
    "NN_2 = KCWrapper(\n",
    "  val_data,\n",
    "  5,\n",
    "  callbacks=[\n",
    "    tf.keras.callbacks.EarlyStopping(\n",
    "      monitor=\"val_loss\", min_delta=0.0001, patience=20, restore_best_weights=True\n",
    "    )\n",
    "  ],\n",
    "  **kerasClassifierParams\n",
    ")\n",
    "\n",
    "grid_dict = { \"scoring\": custom_scores_monk,\n",
    "              \"refit\" : False,\n",
    "              \"cv\" : CV,\n",
    "              \"return_train_score\" : True,\n",
    "              \"n_jobs\" : 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec second kfold for plotting validation learning curves, for early stopping\n",
    "# and to compute mean error and std over 5 inits.\n",
    "# On these criteria, choose the model\n",
    "\n",
    "seed = NN_MONK3_GRID_DICT['model__seed'][0]\n",
    "\n",
    "n_epochs = []\n",
    "\n",
    "for params in top_models['params']:\n",
    "  print(params)\n",
    "\n",
    "  tr_err, tr_acc, ts_err, ts_acc = [], [], [], []\n",
    "  for i in range(seed, seed+5):\n",
    "    print(\"Seed: \" + str(i))\n",
    "\n",
    "    # reset fold counter and histories\n",
    "    reset_counter()   \n",
    "    clear_histories() \n",
    "\n",
    "    # set params and seed\n",
    "    grid_dict['param_grid'] = { field : [value] for (field, value) in params.items() }\n",
    "    grid_dict['param_grid']['model__seed'] = [i]\n",
    "    grid_2 = GridSearchCV(NN_2, **grid_dict)\n",
    "    grid_2.fit(X_train, y_train)\n",
    "\n",
    "    # save mse and accuracy \n",
    "    tr_err.append( grid_2.cv_results_['mean_train_mse'] ) \n",
    "    tr_acc.append( grid_2.cv_results_['mean_train_accuracy'] )\n",
    "    ts_err.append( grid_2.cv_results_['mean_test_mse'] ) \n",
    "    ts_acc.append( grid_2.cv_results_['mean_test_accuracy'] )\n",
    "\n",
    "    # memorize number of epochs (mean over the five folds)\n",
    "    n_epochs.append(mean([ len(get_histories()[i]['loss']) for i in range(5) ]))\n",
    "\n",
    "  print(\"Tr mean accuracy over 5 inits: {:.3f} +/- {:.3f} (std)\\nTr mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\" \\\n",
    "        .format(\n",
    "          mean(tr_acc), std(tr_acc),\n",
    "          mean(tr_err), std(tr_err)\n",
    "        )\n",
    "  )\n",
    "\n",
    "  print(\"Vl mean accuracy over 5 inits: {:.3f} +/- {:.3f} (std)\\nVl mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\" \\\n",
    "        .format(\n",
    "          mean(ts_acc), std(ts_acc),\n",
    "          mean(ts_err), std(ts_err)\n",
    "        )\n",
    "  ) \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Assessment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrain on the whole ds, compute accuracy, mean test error and plot learning curve\n",
    "\n",
    "seed = NN_MONK3_GRID_DICT['model__seed'][0]\n",
    "tr_err, tr_acc, ts_err, ts_acc = [], [], [], []\n",
    "batch_size = kerasClassifierParams['batch_size']\n",
    "\n",
    "# mean test error and std\n",
    "for i in range(seed, seed+5):\n",
    "\n",
    "  NN_monk3_params = { field[7:] : value[0] for (field, value) in NN_MONK3_GRID_DICT.items() }\n",
    "  NN_monk3_params['seed'] = i\n",
    "  NN_monk3 = get_NN(len(X_train.columns), **NN_monk3_params)\n",
    "\n",
    "  h = NN_monk3.fit(X_train, y_train, batch_size=batch_size, epochs=int(mean(n_epochs)),\\\n",
    "    validation_data=(X_test, y_test), shuffle=True, verbose=0)\n",
    "\n",
    "  # save mse and accuracy\n",
    "  tr_score = NN_monk3.evaluate(X_train, y_train, verbose=0)\n",
    "  ts_score = NN_monk3.evaluate(X_test, y_test, verbose=0)\n",
    "  tr_err.append( tr_score[0] ) \n",
    "  ts_err.append( ts_score[0] )\n",
    "\n",
    "# compute accuracy on test set\n",
    "NN_monk3_params['seed'] = seed\n",
    "NN_monk3 = get_NN(len(X_train.columns), **NN_monk3_params)\n",
    "h = NN_monk3.fit(X_train, y_train, batch_size=batch_size, epochs=int(mean(n_epochs)),\\\n",
    "    validation_data=(X_test, y_test), shuffle=True, verbose=0)\n",
    "tr_accuracy = NN_monk3.evaluate(X_train, y_train, verbose=0)[1]\n",
    "ts_accuracy = NN_monk3.evaluate(X_test, y_test, verbose=0)[1]\n",
    "\n",
    "# print results and plot\n",
    "print(\"Tr. accuracy: {:.3f} \\n\".format(tr_accuracy))\n",
    "\n",
    "print(\"Tr. mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\".format( mean(tr_err), std(tr_err) ) )\n",
    "\n",
    "print(\"Ts. accuracy: {:.3f} \\n\".format(ts_accuracy))\n",
    "\n",
    "print(\"Ts. mean mse over 5 inits {:.6f} +/- {:.6f} (std)\\n\".format( mean(ts_err), std(ts_err) ) )\n",
    "\n",
    "do_NN_plot(h.history)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca81cce83a162b5f4a5d747c8d97a71872a701a68cdc138d0312323614df47fd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
